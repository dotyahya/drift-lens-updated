{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce77b14-7423-4809-8947-c9fa841199fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DistilBertConfig, DistilBertModel, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers.pipelines import pipeline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddbec06-2176-413a-aad9-bf9ad1f07412",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55020a9-eebd-41d8-b411-6d773f67289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"use_case/hf-distillbert-ag_news-0-1-2-split66\"\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base_dir,\"dataset\",\"df_train_0_1_2_split_66.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(base_dir,\"dataset\",\"df_test_0_1_2_split_66.csv\"))\n",
    "df_new_unseen = pd.read_csv(os.path.join(base_dir,\"dataset\",\"df_new_unseen_0_1_2_split_66.csv\"))\n",
    "df_drifted = pd.read_csv(os.path.join(base_dir,\"dataset\",\"df_drifted_3_split_66.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b8c66c-f607-477e-882a-b68b114c81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"use_case/hf-distillbert-ag_news-0-1-2-split66/saved_model/best_model\"\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
    "BERT_MODEL = \"distilbert-base-uncased\" \n",
    "\n",
    "config = DistilBertConfig.from_pretrained(os.path.join(OUTPUT_DIR, CONFIG_NAME), output_hidden_states=True)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(os.path.join(OUTPUT_DIR), config=config)\n",
    "model = model.to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67474f-4157-4716-a770-f0aa28400be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name_or_path = \"use_case/hf-bert-ag_news-0-1-2-split66/saved_model/best_model\"\n",
    "\n",
    "#model_2 = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, output_hidden_states=True)\n",
    "#tokenizer_2 = AutoTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n",
    "#pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c32969-72ad-4144-a55f-62b221c27995",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\"padding\":\"max_length\", \"truncation\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c052336-7a00-4c58-8733-ca57ccf40cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_test_preds = pipe(\"money\", **tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca249ad-da8c-48b9-9d54-972b2fd965fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83e3554-8312-4ed4-927d-8e686a22b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1092, -4.9994,  5.0207],\n",
      "        [-2.0539,  5.4114, -4.5275]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(df_test[\"text\"].iloc[:2].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs.to(device))\n",
    "    \n",
    "print(outputs[\"logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86851e-2581-4c7d-afb6-a20108de7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b72ba21-5072-4e20-a56a-db242664e968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[\"hidden_states\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888e739-58f5-4078-bd89-3409674f1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs[\"hidden_states\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199733e8-4c6d-4c39-b749-6c8aa34db832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_np = outputs[\"hidden_states\"][12].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d488b2-3e51-45a5-95d1-d54a6e2a3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_first_tk = hs_np[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe446f-8de6-4115-be9f-16ef279ac3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_first_tk[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c95d59-545b-4244-b876-38b9584e4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_first_tk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ba1dd-2b15-4616-a9d0-ba67a921be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr = np.empty((0,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667548ab-13b4-444e-8011-7aa37c493b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_arr = np.vstack([arr, hs_first_tk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5caf1f-b2a1-4056-bff4-aaa8f3c53a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_arr = np.vstack([new_arr, hs_first_tk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4d980-7f73-4d18-b625-5d4bb83fe423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "#labels = torch.argmax(probabilities, dim=1).tolist()\n",
    "#print(probabilities.tolist())\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efc8f4e7-8abb-4ea3-95a0-888b6e4072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id2label = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaf9d4f0-8683-4761-9411-a5f67eb0eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding_and_predict(model, tokenizer, df):\n",
    "    \n",
    "    X = df[\"text\"].tolist() # List of input texts\n",
    "    Y_original = df[\"label\"].tolist() # List of original labels (GT)\n",
    "    Y_original_names = [train_id2label[l] for l in Y_original]  # List of original labels' names (GT)\n",
    "    E = np.empty((0,768)) # Initialize empty array of embeddings\n",
    "    Y_predicted = [] # Initialize empty list of predicted labels (IDs)\n",
    "    Y_predicted_names = [] # Initialize empty list of predicted labels (Names)\n",
    "    \n",
    "    \n",
    "    BATCH_SIZE = 256\n",
    "    n_batch = len(df)//BATCH_SIZE\n",
    "    remainer = len(df)%BATCH_SIZE\n",
    "    \n",
    "    for i in tqdm(range(n_batch)):\n",
    "        input_texts = df[\"text\"].iloc[i*BATCH_SIZE:i*BATCH_SIZE+BATCH_SIZE].tolist()\n",
    "        \n",
    "        tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_texts.to(device))\n",
    "            \n",
    "        batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "        batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "\n",
    "        batch_probabilities_list = batch_probabilities.tolist()            \n",
    "        batch_labels_name = [train_id2label[l] for l in batch_labels] \n",
    "\n",
    "        Y_predicted.extend(batch_labels)\n",
    "        Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "        last_layer_hidden_states_arr = outputs[\"hidden_states\"][6].detach().cpu().numpy()                   \n",
    "        embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :] # [BATCH_SIZE, 0 = CLS, 768]\n",
    "        E = np.vstack([E, embedding_CLS_arr])\n",
    "            \n",
    "    input_texts = df[\"text\"].iloc[-remainer:].tolist()\n",
    "        \n",
    "    tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_texts.to(device))\n",
    "\n",
    "    batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "    batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "\n",
    "    batch_probabilities_list = batch_probabilities.tolist()            \n",
    "    batch_labels_name = [train_id2label[l] for l in batch_labels] \n",
    "\n",
    "    Y_predicted.extend(batch_labels)\n",
    "    Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "    last_layer_hidden_states_arr = outputs[\"hidden_states\"][6].detach().cpu().numpy()                   \n",
    "    embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :] # [BATCH_SIZE, 0 = CLS, 768]\n",
    "    E = np.vstack([E, embedding_CLS_arr])\n",
    "        \n",
    "    return X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7df62e0-255e-4c5e-af16-847e2c1f4ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:11<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, E_test, Y_original_test, Y_original_names_test, Y_predicted_test, Y_predicted_names_test = extract_embedding_and_predict(model, tokenizer, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "701b1c63-cf2f-4b34-8fc4-017fe11a90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [02:28<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, E_train, Y_original_train, Y_original_names_train, Y_predicted_train, Y_predicted_names_train = extract_embedding_and_predict(model, tokenizer, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11d0900c-4589-4a10-8a07-ae08a8be619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [01:27<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_drift, E_drift, Y_original_drift, Y_original_names_drift, Y_predicted_drift, Y_predicted_names_drift = extract_embedding_and_predict(model, tokenizer, df_drifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39157c46-3728-4223-87ce-a96612221846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [01:11<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X_new_unseen, E_new_unseen, Y_original_new_unseen, Y_original_names_new_unseen, Y_predicted_new_unseen, Y_predicted_names_new_unseen = extract_embedding_and_predict(model, tokenizer, df_new_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a774c00-1e89-46af-9e46-3f3b2beacd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da0c8ff-a57a-4b85-b64f-e2a03a9177a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(output_path, X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names):\n",
    "\n",
    "    fp = h5py.File(output_path, \"w\")\n",
    "\n",
    "    fp.create_dataset(\"X\", data=X, compression=\"gzip\")\n",
    "    fp.create_dataset(\"E\", data=E, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original\", data=Y_original, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original_names\", data=Y_original_names, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted\", data=Y_predicted, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted_names\", data=Y_predicted_names, compression=\"gzip\")\n",
    "    fp.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9927406b-ca13-49e1-bbe3-8aa75d011878",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dir = os.path.join(base_dir, \"saved_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ad112a7-9503-43a7-a7f2-98d0ab7b5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(os.path.join(embedding_dir, \"train_embedding_0_1_2.hdf5\"), \n",
    "                X_train, \n",
    "                E_train, \n",
    "                Y_original_train, \n",
    "                Y_original_names_train, \n",
    "                Y_predicted_train, \n",
    "                Y_predicted_names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f8b3385-fec1-45e6-8a62-4fa90633b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(os.path.join(embedding_dir, \"test_embedding_0_1_2.hdf5\"), \n",
    "                X_test, \n",
    "                E_test, \n",
    "                Y_original_test, \n",
    "                Y_original_names_test, \n",
    "                Y_predicted_test, \n",
    "                Y_predicted_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c2356f6-3ebd-43a7-99cf-acd4852021fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(os.path.join(embedding_dir, \"drifted_embedding_3.hdf5\"), \n",
    "                X_drift, \n",
    "                E_drift, \n",
    "                Y_original_drift, \n",
    "                Y_original_names_drift, \n",
    "                Y_predicted_drift, \n",
    "                Y_predicted_names_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31394014-b40e-4738-b284-21a90600f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(os.path.join(embedding_dir, \"new_unseen_embedding_0_1_2.hdf5\"), \n",
    "                X_new_unseen, \n",
    "                E_new_unseen, \n",
    "                Y_original_new_unseen, \n",
    "                Y_original_names_new_unseen, \n",
    "                Y_predicted_new_unseen, \n",
    "                Y_predicted_names_new_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b4fc7-0e0b-4849-8d54-9c708abcae73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-env",
   "language": "python",
   "name": "audio-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
