{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use Case 1: Embeddings extraction from the BERT model for topic classification on Ag News"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s289159/.conda/envs/audio-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertTokenizer,BertForSequenceClassification, BertConfig\n",
    "from transformers.pipelines import pipeline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import h5py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddbec06-2176-413a-aad9-bf9ad1f07412",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55020a9-eebd-41d8-b411-6d773f67289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"static/data/bert\"\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(data_dir,\"df_train_0_1_2.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_dir,\"df_test_0_1_2.csv\"))\n",
    "df_new_unseen = pd.read_csv(os.path.join(data_dir,\"df_new_unseen_0_1_2.csv\"))\n",
    "df_drifted = pd.read_csv(os.path.join(data_dir,\"df_drifted_3.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b8c66c-f607-477e-882a-b68b114c81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"static/saved_models/bert/best_model\"\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
    "BERT_MODEL = 'bert-base-uncased' # BERT model type\n",
    "\n",
    "config = BertConfig.from_pretrained(os.path.join(MODEL_DIR, CONFIG_NAME), output_hidden_states=True)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR), config=config)\n",
    "model = model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c32969-72ad-4144-a55f-62b221c27995",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\"padding\":\"max_length\", \"truncation\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc8f4e7-8abb-4ea3-95a0-888b6e4072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id2label = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf9d4f0-8683-4761-9411-a5f67eb0eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding_and_predict(model, tokenizer, df, layer_id):\n",
    "    \n",
    "    X = df[\"text\"].tolist() # List of input texts\n",
    "    Y_original = df[\"label\"].tolist() # List of original labels (GT)\n",
    "    Y_original_names = [train_id2label[l] for l in Y_original]  # List of original labels' names (GT)\n",
    "    E = np.empty((0,768)) # Initialize empty array of embeddings\n",
    "    Y_predicted = [] # Initialize empty list of predicted labels (IDs)\n",
    "    Y_predicted_names = [] # Initialize empty list of predicted labels (Names)\n",
    "    \n",
    "    \n",
    "    BATCH_SIZE = 256\n",
    "    n_batch = len(df)//BATCH_SIZE\n",
    "    remainer = len(df)%BATCH_SIZE\n",
    "    \n",
    "    for i in tqdm(range(n_batch)):\n",
    "        input_texts = df[\"text\"].iloc[i*BATCH_SIZE:i*BATCH_SIZE+BATCH_SIZE].tolist()\n",
    "        \n",
    "        tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_texts.to(device))\n",
    "            \n",
    "        batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "        batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "\n",
    "        batch_probabilities_list = batch_probabilities.tolist()            \n",
    "        batch_labels_name = [train_id2label[l] for l in batch_labels] \n",
    "\n",
    "        Y_predicted.extend(batch_labels)\n",
    "        Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "        last_layer_hidden_states_arr = outputs[\"hidden_states\"][layer_id].detach().cpu().numpy()                   \n",
    "        embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :] # [BATCH_SIZE, 0 = CLS, 768]\n",
    "        E = np.vstack([E, embedding_CLS_arr])\n",
    "            \n",
    "           \n",
    "    if remainer>0:\n",
    "\n",
    "        input_texts = df[\"text\"].iloc[-remainer:].tolist()\n",
    "\n",
    "        tokenized_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_texts.to(device))\n",
    "\n",
    "        batch_probabilities = nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
    "        batch_labels = torch.argmax(batch_probabilities, dim=1).tolist()\n",
    "\n",
    "        batch_probabilities_list = batch_probabilities.tolist()            \n",
    "        batch_labels_name = [train_id2label[l] for l in batch_labels] \n",
    "\n",
    "        Y_predicted.extend(batch_labels)\n",
    "        Y_predicted_names.extend(batch_labels_name)\n",
    "\n",
    "        last_layer_hidden_states_arr = outputs[\"hidden_states\"][layer_id].detach().cpu().numpy()                   \n",
    "        embedding_CLS_arr = last_layer_hidden_states_arr[:, 0, :] # [BATCH_SIZE, 0 = CLS, 768]\n",
    "        E = np.vstack([E, embedding_CLS_arr])\n",
    "\n",
    "        return X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b19a52-9ac1-40b7-a44f-135ef91353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(output_path, X, E, Y_original, Y_original_names, Y_predicted, Y_predicted_names):\n",
    "\n",
    "    fp = h5py.File(output_path, \"w\")\n",
    "\n",
    "    fp.create_dataset(\"X\", data=X, compression=\"gzip\")\n",
    "    fp.create_dataset(\"E\", data=E, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original\", data=Y_original, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_original_names\", data=Y_original_names, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted\", data=Y_predicted, compression=\"gzip\")\n",
    "    fp.create_dataset(\"Y_predicted_names\", data=Y_predicted_names, compression=\"gzip\")\n",
    "    fp.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7df62e0-255e-4c5e-af16-847e2c1f4ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.26it/s]\n",
      "100%|██████████| 232/232 [03:31<00:00,  1.10it/s]\n",
      "100%|██████████| 124/124 [02:13<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.28it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:13<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.28it/s]\n",
      "100%|██████████| 232/232 [03:31<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:13<00:00,  1.08s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:13<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.28it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:13<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.28it/s]\n",
      "100%|██████████| 232/232 [03:32<00:00,  1.09it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 232/232 [03:31<00:00,  1.10it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:43<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:17<00:00,  1.28it/s]\n",
      "100%|██████████| 232/232 [03:31<00:00,  1.10it/s]\n",
      "100%|██████████| 124/124 [02:12<00:00,  1.07s/it]\n",
      "100%|██████████| 119/119 [01:44<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_dir = os.path.join(\"static\", \"saved_embeddings\", \"bert\")\n",
    "\n",
    "for layer_id in range(1,12):\n",
    "    print(\"layer: \",layer_id)\n",
    "\n",
    "    X_test, E_test, Y_original_test, Y_original_names_test, Y_predicted_test, Y_predicted_names_test = extract_embedding_and_predict(model, tokenizer, df_test, layer_id)\n",
    "\n",
    "    X_train, E_train, Y_original_train, Y_original_names_train, Y_predicted_train, Y_predicted_names_train = extract_embedding_and_predict(model, tokenizer, df_train, layer_id)\n",
    "\n",
    "    X_drift, E_drift, Y_original_drift, Y_original_names_drift, Y_predicted_drift, Y_predicted_names_drift = extract_embedding_and_predict(model, tokenizer, df_drifted, layer_id)\n",
    "\n",
    "    X_new_unseen, E_new_unseen, Y_original_new_unseen, Y_original_names_new_unseen, Y_predicted_new_unseen, Y_predicted_names_new_unseen = extract_embedding_and_predict(model, tokenizer, df_new_unseen, layer_id)\n",
    "\n",
    "    save_embedding(os.path.join(embedding_dir, f\"train_embedding_0_1_2_layer_{layer_id}.hdf5\"), \n",
    "                    X_train, \n",
    "                    E_train, \n",
    "                    Y_original_train, \n",
    "                    Y_original_names_train, \n",
    "                    Y_predicted_train, \n",
    "                    Y_predicted_names_train)\n",
    "\n",
    "    save_embedding(os.path.join(embedding_dir, f\"test_embedding_0_1_2_layer_{layer_id}.hdf5\"), \n",
    "                    X_test, \n",
    "                    E_test, \n",
    "                    Y_original_test, \n",
    "                    Y_original_names_test, \n",
    "                    Y_predicted_test, \n",
    "                    Y_predicted_names_test)\n",
    "\n",
    "    save_embedding(os.path.join(embedding_dir, f\"drifted_embedding_3_layer_{layer_id}.hdf5\"), \n",
    "                    X_drift, \n",
    "                    E_drift, \n",
    "                    Y_original_drift, \n",
    "                    Y_original_names_drift, \n",
    "                    Y_predicted_drift, \n",
    "                    Y_predicted_names_drift)\n",
    "\n",
    "    save_embedding(os.path.join(embedding_dir, f\"new_unseen_embedding_0_1_2_layer_{layer_id}.hdf5\"), \n",
    "                    X_new_unseen, \n",
    "                    E_new_unseen, \n",
    "                    Y_original_new_unseen, \n",
    "                    Y_original_names_new_unseen, \n",
    "                    Y_predicted_new_unseen, \n",
    "                    Y_predicted_names_new_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b1c63-cf2f-4b34-8fc4-017fe11a90a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0900c-4589-4a10-8a07-ae08a8be619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39157c46-3728-4223-87ce-a96612221846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a774c00-1e89-46af-9e46-3f3b2beacd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0c8ff-a57a-4b85-b64f-e2a03a9177a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927406b-ca13-49e1-bbe3-8aa75d011878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad112a7-9503-43a7-a7f2-98d0ab7b5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b3385-fec1-45e6-8a62-4fa90633b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2356f6-3ebd-43a7-99cf-acd4852021fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31394014-b40e-4738-b284-21a90600f8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b4fc7-0e0b-4849-8d54-9c708abcae73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-env",
   "language": "python",
   "name": "audio-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}