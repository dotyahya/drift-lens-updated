{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823968be-28f0-43bd-9869-fd8d1be9b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Load images from a pickle file\n",
    "with open(\"stl_test.pickle\", \"rb\") as tr_images_file:\n",
    "    test = pickle.load(tr_images_file)\n",
    "with open(\"stl_train.pickle\", \"rb\") as tr_images_file:\n",
    "    train = pickle.load(tr_images_file)\n",
    "with open(\"stl_val.pickle\", \"rb\") as tr_images_file:\n",
    "    new = pickle.load(tr_images_file)\n",
    "with open(\"stl_deg.pickle\", \"rb\") as tr_images_file:\n",
    "    deg = pickle.load(tr_images_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c6d656-2d8d-409a-9059-6679f5d03d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n",
      "exceptions\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def unpk(data):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    c=0\n",
    "    tot=[]\n",
    "    for pair in data:\n",
    "        try:\n",
    "            img=np.array(pair[0]).reshape((96,96,3))\n",
    "            x.append(img)\n",
    "            y.append(pair[1])\n",
    "        except Exception as e:\n",
    "            c=c+1\n",
    "    \n",
    "    print(\"exceptions\")\n",
    "    print(c)\n",
    "    return x, y\n",
    "\n",
    "#unpk opens the pickle files and separates images from labels \n",
    "\n",
    "x_train,y_trai=unpk(train)\n",
    "x_test,y_tes=unpk(test)\n",
    "x_new, y_ne=unpk(new)\n",
    "x_deg, y_deg=unpk(deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7d1eb5-d6ba-44a4-a9db-2cca1f64f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "5850\n",
      "test data:\n",
      "2925\n",
      "new unseen data:\n",
      "2925\n",
      "extra training label, class truck:\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "print(\"train data:\")\n",
    "print(len(x_train))\n",
    "print(\"test data:\")\n",
    "print(len(x_test))\n",
    "print(\"new unseen data:\")\n",
    "print(len(x_new))\n",
    "print(\"extra training label, class truck:\")\n",
    "print(len(x_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef3ba54-7cb6-4f9e-97b0-c562b797ec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n",
      "3250\n",
      "3250\n"
     ]
    }
   ],
   "source": [
    "#since in precedence the drift was simulated by adding an extra class we reintegrate the class with\n",
    "#other data\n",
    "for i in range(len(x_deg)):\n",
    "    if i<650:\n",
    "        x_train.append(x_deg[i])\n",
    "        y_trai.append(y_deg[i])\n",
    "    elif i>=650 and i<975:\n",
    "        x_test.append(x_deg[i])\n",
    "        y_tes.append(y_deg[i])\n",
    "    else:\n",
    "        x_new.append(x_deg[i])\n",
    "        y_ne.append(y_deg[i])\n",
    "        \n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(x_new))\n",
    "#print(len(x_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e9d203-e7fa-46c8-8f32-b8e9d91cdade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFilter, ImageDraw, ImageOps\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "def blur_inside_percentage_of_image(image_array, percentage):\n",
    "    # Open the image\n",
    "    #img = Image.open(image_path)\n",
    "    img=Image.fromarray(image_array)\n",
    "    # Get the dimensions of the image\n",
    "    width, height = img.size\n",
    "    area=width*height\n",
    "\n",
    "    # Calculate the spot size based on the percentage of the image dimensions\n",
    "    circ_area=int(area* percentage / 100)\n",
    "    spot_size_rad=int(np.sqrt(circ_area/3.14))\n",
    "    spot_size=2*spot_size_rad\n",
    "    # Define the coordinates for the center of the image\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "\n",
    "    # Create a circular mask\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((center_x - spot_size // 2, center_y - spot_size // 2,\n",
    "                  center_x + spot_size // 2, center_y + spot_size // 2), fill=255)\n",
    "\n",
    "    # Invert the circular mask\n",
    "    inverted_mask = ImageOps.invert(mask)\n",
    "\n",
    "    # Blur the inside of the circular area using the inverted mask\n",
    "    blurred_img = img.filter(ImageFilter.GaussianBlur(radius=8))  # Adjust radius as needed\n",
    "    blurred_img.paste(img, mask=inverted_mask)\n",
    "    final_array = np.array(blurred_img).reshape((96,96,3))\n",
    "    \n",
    "    return final_array\n",
    "#in this step we blur the images\n",
    "#if prc=0 then the images have no blur and belong to the new unseen data set\n",
    "prc=20  # Adjust the percentage as needed, this parameter impacts the area blurred\n",
    "\n",
    "blur_images=[]\n",
    "for i in range(len(x_new)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    tmp=x_new[i]\n",
    "    blur_images.append(blur_inside_percentage_of_image(x_new[i], prc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea9b125-7cde-4ada-9854-1a0023c7bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "x_blur=np.array(blur_images)\n",
    "#x_deg=np.array(b_t_images)\n",
    "y_train=np.array(y_trai)\n",
    "y_test=np.array(y_tes)\n",
    "y_blur=np.array(y_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ba7c16-eb71-42c6-a522-ec65052a71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "6500\n",
      "test\n",
      "3250\n",
      "blur\n",
      "3250\n"
     ]
    }
   ],
   "source": [
    "def create_ds(im, lab):\n",
    "    ds=[]\n",
    "    for i in range(len(im)):\n",
    "        ds.append((im[i],lab[i]))\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "train_ds=create_ds(x_train, y_train)\n",
    "test_ds=create_ds(x_test, y_test)\n",
    "blur_ds=create_ds(x_blur, y_blur)\n",
    "\n",
    "\n",
    "print(\"train\")   \n",
    "print(len(train_ds))\n",
    "print(\"test\")\n",
    "print(len(test_ds))\n",
    "print(\"blur\")\n",
    "print(len(blur_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34c1957-60dc-4e06-bd9a-0f0fb861c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, num_labels=10):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        if loss is not None:\n",
    "          return logits, loss.item()\n",
    "        else:\n",
    "          return logits, None\n",
    "    \n",
    "    def emb_extr_new_v1(self, pixel_values):\n",
    "        \n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        #output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        #for layer in model.children():\n",
    "        \n",
    "        return outputs.last_hidden_state[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8622d282-8df9-407f-9833-7db46748befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 2e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1708c354-3387-41ea-a678-2f69df88ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0dc51ee5c94d018b4935947631b61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb8063f292d4a38ba7364f18a7f7c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330e7c4738a749ea913291fdd72dcc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# Define Model\n",
    "model = ViTForImageClassification(10)    \n",
    "# Feature Extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Cross Entropy Loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# Use GPU if available  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2bb5826-7626-42c2-bb99-341bcdba19c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Epoch:  0 | train loss: 2.3218 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 1.7114 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.9529 | test accuracy: 1.00\n",
      "Epoch:  1 | train loss: 0.7638 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.5512 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.3581 | test accuracy: 1.00\n",
      "Epoch:  2 | train loss: 0.3394 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.2670 | test accuracy: 1.00\n",
      "Epoch:  2 | train loss: 0.2493 | test accuracy: 1.00\n",
      "Epoch:  3 | train loss: 0.2241 | test accuracy: 0.98\n",
      "Epoch:  3 | train loss: 0.1976 | test accuracy: 0.96\n",
      "Epoch:  3 | train loss: 0.3393 | test accuracy: 0.94\n",
      "Epoch:  4 | train loss: 0.2385 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.2005 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.1604 | test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "#load data into train and test loader and start traininig phase\n",
    "train_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_loader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "print(\"training...\")\n",
    "# Train the model\n",
    "for epoch in range(EPOCHS):        \n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        # Change input array into list with each batch being one element\n",
    "        x = np.split(np.squeeze(np.array(x)), BATCH_SIZE)\n",
    "        # Remove unecessary dimension\n",
    "        for index, array in enumerate(x):\n",
    "            x[index] = np.squeeze(array)\n",
    "        # Apply feature extractor, stack back into 1 tensor and then convert to tensor\n",
    "        x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n",
    "        # Send to GPU if available\n",
    "        x, y  = x.to(device), y.to(device)\n",
    "        b_x = Variable(x)   # batch x (image)\n",
    "        b_y = Variable(y)   # batch y (target)\n",
    "        # Feed through model\n",
    "        output, loss = model(b_x, None)\n",
    "        # Calculate loss\n",
    "        if loss is None: \n",
    "            loss = loss_func(output, b_y)   \n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()                 \n",
    "            optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            # Get the next batch for testing purposes\n",
    "            test = next(iter(test_loader))\n",
    "            test_x = test[0]\n",
    "            # Reshape and get feature matrices as needed\n",
    "            test_x = np.split(np.squeeze(np.array(test_x)), BATCH_SIZE)\n",
    "            for index, array in enumerate(test_x):\n",
    "                test_x[index] = np.squeeze(array)\n",
    "            test_x = torch.tensor(np.stack(feature_extractor(test_x)['pixel_values'], axis=0))\n",
    "            # Send to appropirate computing device\n",
    "            test_x = test_x.to(device)\n",
    "            test_y = test[1].to(device)\n",
    "            # Get output (+ respective class) and compare to target\n",
    "            test_output, loss = model(test_x, test_y)\n",
    "            test_output = test_output.argmax(1)\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss, '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d985a5d2-9caa-485e-b6a7-fe0c11fa0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation...\n",
      "[[310   0   9   0   0   1   2   0   0   3]\n",
      " [  0 306   0  17   0   2   0   0   0   0]\n",
      " [ 17   0 288   0   1   1   5   0   7   6]\n",
      " [  0   4   0 317   0   1   0   3   0   0]\n",
      " [  5   0   1   0 309   3   7   0   0   0]\n",
      " [  0   1   0   1   0 319   0   4   0   0]\n",
      " [  5   0   0   0   3   1 315   0   0   1]\n",
      " [  0   0   0   3   0   3   0 319   0   0]\n",
      " [  1   0   1   1   0   0   2   0 314   6]\n",
      " [  4   0   1   0   0   0   1   0   1 318]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       325\n",
      "           1       0.98      0.94      0.96       325\n",
      "           2       0.96      0.89      0.92       325\n",
      "           3       0.94      0.98      0.95       325\n",
      "           4       0.99      0.95      0.97       325\n",
      "           5       0.96      0.98      0.97       325\n",
      "           6       0.95      0.97      0.96       325\n",
      "           7       0.98      0.98      0.98       325\n",
      "           8       0.98      0.97      0.97       325\n",
      "           9       0.95      0.98      0.97       325\n",
      "\n",
      "    accuracy                           0.96      3250\n",
      "   macro avg       0.96      0.96      0.96      3250\n",
      "weighted avg       0.96      0.96      0.96      3250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Load the test dataset from pickle\n",
    "\n",
    "#test_data =test_ds\n",
    "\n",
    "# Define a custom dataset class for the test set\n",
    "class CustomTestDataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index]\n",
    "        # Perform any necessary preprocessing on the image\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(Image.fromarray(image))\n",
    "        return image, label\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataset = CustomTestDataset(test_ds)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Perform inference on the test set\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "print(\"evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs, loss = model(inputs, labels)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        #all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(confusion_matrix(all_labels, all_predictions))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5e7e93-fe8b-42dd-a239-f718ee56395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inizio evaluation...\n",
      "[[274   0   6   3  10   5  11   1   3  12]\n",
      " [  0 276   0  34   0  15   0   0   0   0]\n",
      " [ 33   0 224   1  18   4   8   0  21  16]\n",
      " [  0   1   0 291   0  11   0  22   0   0]\n",
      " [  0   0   2   2 307  13   1   0   0   0]\n",
      " [  0   0   0   2   0 302   0  20   0   1]\n",
      " [  6   0   6   0  29   3 273   1   3   4]\n",
      " [  0   0   0   2   0   9   0 314   0   0]\n",
      " [  0   0   1   2   3   3   2   1 301  12]\n",
      " [  5   0   2   0  10   2   1   0   1 304]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       325\n",
      "           1       1.00      0.85      0.92       325\n",
      "           2       0.93      0.69      0.79       325\n",
      "           3       0.86      0.90      0.88       325\n",
      "           4       0.81      0.94      0.87       325\n",
      "           5       0.82      0.93      0.87       325\n",
      "           6       0.92      0.84      0.88       325\n",
      "           7       0.87      0.97      0.92       325\n",
      "           8       0.91      0.93      0.92       325\n",
      "           9       0.87      0.94      0.90       325\n",
      "\n",
      "    accuracy                           0.88      3250\n",
      "   macro avg       0.89      0.88      0.88      3250\n",
      "weighted avg       0.89      0.88      0.88      3250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blur_dataset = CustomTestDataset(blur_ds)\n",
    "blur_dataloader = data.DataLoader(blur_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Perform inference on the test set\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "print(\"start evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in blur_dataloader:\n",
    "        outputs, loss = model(inputs, labels)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        #all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(confusion_matrix(all_labels, all_predictions))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c563aaf-c290-4feb-b084-19d768501bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blur\n",
      "inizio extraction embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150/3811817293.py:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  embeddings=np.array(embeddings, dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "inizio extraction embedding...\n",
      "test\n",
      "inizio extraction embedding...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def embedding_extraction(modello, dataloader):\n",
    "    \n",
    "    embeddings=[]\n",
    "    print(\"start embedding extraction...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = []\n",
    "\n",
    "        for images, _ in dataloader:  # Adjust this loop based on your data loading\n",
    "            outputs = modello.emb_extr_new_v1(images)\n",
    "            #emb_extr_new_v1\n",
    "            embeddings.append(outputs)\n",
    "            \n",
    "    embeddings=np.array(embeddings, dtype='object')\n",
    "            \n",
    "    return embeddings\n",
    "\n",
    "def into_dataloader(ds):\n",
    "    dataset = CustomTestDataset(ds)\n",
    "    dataloader = data.DataLoader(dataset, batch_size=50, shuffle=False)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "train_emb=embedding_extraction(model, into_dataloader(train_ds))\n",
    "print(\"test\")\n",
    "test_emb=embedding_extraction(model, into_dataloader(test_ds))\n",
    "print(\"blur\")\n",
    "blur_emb=embedding_extraction(model, into_dataloader(blur_ds))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a61cecea-7d88-4014-b395-9862ffd8256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions...\n",
      "train\n",
      "inizio evaluation...\n",
      "test\n",
      "inizio evaluation...\n",
      "blur\n",
      "inizio evaluation...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def prediction_extraction(modello, dataloader):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    print(\"start evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs, loss = modello(inputs, labels=None)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            #all_embeddings.append(embeddings.cpu().numpy())\n",
    "            \n",
    "    return all_predictions, all_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"predictions...\")\n",
    "print(\"train\")\n",
    "train_pred, train_lab=prediction_extraction(model, into_dataloader(train_ds))\n",
    "print(\"test\")\n",
    "test_pred, test_lab=prediction_extraction(model, into_dataloader(test_ds))\n",
    "print(\"blur\")\n",
    "blur_pred, blur_lab=prediction_extraction(model, into_dataloader(blur_ds))\n",
    "#print(\"deg\")\n",
    "#deg_pred, deg_lab=prediction_extraction(model, into_dataloader(drift))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5e43959-65d3-488e-b7c5-3f3086e44d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debatching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150/2065555189.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  final_e=np.array(final_e, dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def de_batch(emb):\n",
    "    final_e=[]\n",
    "    for i in range(len(emb)):\n",
    "        for j in range(len(emb[i])):\n",
    "            final_e.append(emb[i][j])\n",
    "    \n",
    "    final_e=np.array(final_e, dtype='object')\n",
    "    return final_e\n",
    "\n",
    "print(\"debatching...\")\n",
    "\n",
    "final_train_emb=de_batch(train_emb)\n",
    "final_test_emb=de_batch(test_emb)\n",
    "final_blur_emb=de_batch(blur_emb)\n",
    "#final_deg_emb=de_batch(deg_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0074cdbf-a2cc-422f-85f5-90ccdc658ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "test...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "blur...\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def final_step(dati):\n",
    "    temp=[]\n",
    "    for i in range(len(dati)):\n",
    "        if i%500==0:\n",
    "            print(i)\n",
    "        tmp=[]\n",
    "        for j in range(len(dati[i])):\n",
    "            tmp.append(dati[i][j])\n",
    "        temp.append(np.array(tmp))\n",
    "    \n",
    "    temp=np.array(temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "print(\"train...\")\n",
    "fin_train_emb=final_step(final_train_emb)\n",
    "print(\"test...\")\n",
    "fin_test_emb=final_step(final_test_emb)\n",
    "print(\"blur...\")\n",
    "fin_blur_emb=final_step(final_blur_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a685b07d-6c15-4f9e-9762-85148dac528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings saved\n",
      "embeddings saved\n",
      "embeddings saved\n",
      "finito\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def save_data(path, data):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(data, handle)\n",
    "    print(path)\n",
    "    print(\"saved\")\n",
    "\n",
    "def save_embeddings(embedding, true_label,pr_label, path):\n",
    "    fp = h5py.File(path, \"w\")\n",
    "    fp.create_dataset(\"E\", data=embedding, compression=\"gzip\")    \n",
    "    fp.create_dataset(\"Y_predicted\", data=pr_label, compression=\"gzip\") \n",
    "    fp.create_dataset(\"Y_original\", data=true_label, compression=\"gzip\") \n",
    "    fp.close()\n",
    "    print(\"embeddings saved\")\n",
    "\n",
    "train_path=\"Stl_train_emb_v1\"\n",
    "test_path=\"Stl_test_emb_v1\"\n",
    "blur_path=\"Stl_new_unseen_emb\"\n",
    "#deg_path=\"Stl_deg_emb\"\n",
    "\n",
    "save_embeddings(fin_train_emb, train_lab, train_pred, train_path )\n",
    "save_embeddings(fin_test_emb, test_lab, test_pred, test_path )\n",
    "save_embeddings(fin_blur_emb, blur_lab, blur_pred, blur_path)\n",
    "#save_embeddings(fin_deg_emb, deg_lab, deg_pred, deg_path)\n",
    "\n",
    "#save_data(\"train_stl.pickle\",train_ds)\n",
    "#save_data(\"test_stl.pickle\",test_ds)\n",
    "#save_data(\"blur_stl.pickle\",blur_ds)\n",
    "#save_data(\"deg_stl.pickle\",drift)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c20e3-dce8-4d87-9399-375571fc6e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}